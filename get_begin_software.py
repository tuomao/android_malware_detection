# coding: utf-8
__author__ = 'tuomao'
from bs4 import  BeautifulSoup
import urllib2
import urlparse
category_url={
    'security':'http://zhushou.360.cn/list/index/cid/11/',
    'social':'http://zhushou.360.cn/list/index/cid/12/',
    'movie':'http://zhushou.360.cn/list/index/cid/14/',
    'news':'http://zhushou.360.cn/list/index/cid/15/',
    'life':'http://zhushou.360.cn/list/index/cid/16/',
    'theme_wallpaper':'http://zhushou.360.cn/list/index/cid/18/',
    'office':'http://zhushou.360.cn/list/index/cid/17/',
    'shooting':'http://zhushou.360.cn/list/index/cid/102228/',
    'buy':'http://zhushou.360.cn/list/index/cid/102230/',
    'map':'http://zhushou.360.cn/list/index/cid/102231/',
    'study':'http://zhushou.360.cn/list/index/cid/102232/',
    'money':'http://zhushou.360.cn/list/index/cid/102139/',
    'healthy':'http://zhushou.360.cn/list/index/cid/102233/'
}
apk_urls=[]
def extract_apps_from_category(category,doc):
    soup=BeautifulSoup(doc)
    apps=soup.find(attrs={'class':'iconList'}).find_all('a')
    for app in apps:
        try:
            url=app['href']
            url=url.split('&')
            if isinstance(url,list):
                apk_url=url[-1]
                if(apk_url.endswith('.apk')):
                    apk_url=apk_url.split('=')[-1]
                    apk_urls.append({apk_url.encode('utf-8'):category})
        except Exception as e:
            print(e)

def main():
    for key,value in category_url.items():
        # 分别取5页的数据
        for page in range(5):
            url='%s?page=%d'%(value,page)
            print(url)
            doc=urllib2.urlopen(url).read()
            extract_apps_from_category(key,doc)
    out=open('./output.txt','w+')
    for url in apk_urls:
        out.write(str(url)+'\n')
    out.flush()
    out.close()
main()
