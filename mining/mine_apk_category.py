#coding: utf-8
from numpy.lib._compiled_base import interp
from sklearn import metrics, cross_validation, grid_search, tree, svm
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile, f_classif, f_regression
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn.preprocessing import label_binarize
import torndb
import numpy as np
from model import dbsetting
from model.db_tool import DbTool
import matplotlib.pyplot as plt

db=torndb.Connection(**dbsetting.DATABASE['mysql-remote'])
db_tool=DbTool(db)


def main():

    # get data
    train_data,permission_list=db_tool.get_new_train_data()
    X_train, X_test, y_train, y_test = cross_validation.train_test_split(train_data['permission-data'],
            train_data['target'], test_size=0.1, random_state=1)

    f_number=[5,6,7,8,10,15,20,30,40,50]
    for f in f_number:
        selector = SelectKBest(chi2, k=f)
        x_train_in=selector.fit_transform(X_train,y_train)
        x_test_in=selector.transform(X_test)

        # # build the model
        # clss=[GaussianNB(),MultinomialNB(),BernoulliNB(),tree.DecisionTreeClassifier(),svm.SVC(decision_function_shape='ovo')]
        clss=[GaussianNB()]
        for cls in clss:
            model = cls.fit(x_train_in, y_train)
            # # valid the model
            predicted = model.predict(x_test_in)
            print ('%d,%f'%(f,metrics.accuracy_score(y_test, predicted)))
            print(metrics.classification_report(y_test, predicted))

def k_cross_validate():
    vectorizer = CountVectorizer(decode_error='ignore')
    ch2 = SelectKBest(chi2, k=15)

    # get data
    train_data,feature_names=db_tool.get_new_train_data()

    # feature extraction
    X_data=ch2.fit_transform(train_data['permission-data'],train_data['target'])

    # # build the model
    clf = MultinomialNB()

    print(X_data.shape)
    # valid the model
    predicted=cross_validation.cross_val_predict(clf, X_data,train_data['target'],cv=3)
    print(metrics.classification_report(train_data['target'], predicted))


def gridSearchCV_test():

    ch2 = SelectKBest(chi2, k=20)

    # get data
    train_data=db_tool.get_new_train_data()
    X_train, X_test, y_train, y_test = cross_validation.train_test_split(train_data['permission-data'],
            train_data['target'], test_size=0.2, random_state=1)


    X_train=ch2.fit_transform(X_train,y_train)
    X_test=ch2.transform(X_test)

    param_grid=[
        {'alpha':[1,0.4,10],'fit_prior':[True,False]},
        {'alpha':[0,9,0.4],'fit_prior':[True]}
    ]
    clf = grid_search.GridSearchCV(MultinomialNB(), param_grid)
    # # build the model
    clf.fit(X_train, y_train)

    print(clf.best_params_)
    print()
    print("Grid scores on development set:")
    print()
    for params, mean_score, scores in clf.grid_scores_:
        print("%0.3f (+/-%0.03f) for %r"
              % (mean_score, scores.std() * 2, params))

    predicted = clf.predict(X_test)
    print (metrics.accuracy_score(y_test, predicted))
    print(metrics.classification_report(y_test, predicted))


def permission_selection():
    # get data
    train_data,permission_list=db_tool.get_new_train_data()
    feature_names=permission_list
    print(len(feature_names))

    score_functions=[chi2]
    for f in score_functions:
        selector = SelectKBest(f, k=15)
        x_train=selector.fit_transform(train_data['permission-data'],train_data['target'])
        select_feature_names=[feature_names[index] for index in selector.get_support(indices=True)]

        print(select_feature_names)
        # # build the model
        clf = MultinomialNB()

        # valid the model
        predicted=cross_validation.cross_val_predict(clf, x_train,train_data['target'],cv=10)
        print(metrics.accuracy_score(train_data['target'], predicted))


def string_selection():
    # get data
    vectorizer = CountVectorizer(decode_error='ignore')
    ch2 = SelectKBest(chi2, k=100)

    # get data
    train_data,permission_list=db_tool.get_new_train_data()
    x_train, x_test, y_train, y_test = cross_validation.train_test_split(train_data['string-data'],
            train_data['target'], test_size=0.2, random_state=1)

    # feature extraction
    x_train=vectorizer.fit_transform(x_train)
    feature_names = vectorizer.get_feature_names()

    x_train=ch2.fit_transform(x_train,y_train)
    feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]
    print(ch2.scores_)
    print(ch2.get_support(indices=True))
    print(feature_names)
    x_test=vectorizer.transform(x_test)
    x_test=ch2.transform(x_test)

    # # build the model
    model = MultinomialNB().fit(x_train, y_train)
    #
    # # valid the model
    predicted = model.predict(x_test)
    print (metrics.accuracy_score(y_test, predicted))


def permission_roc():

    # get data
    train_data,permission_list=db_tool.get_new_train_data()
    y=train_data['target']

    x_train, x_test, y_train, y_test = cross_validation.train_test_split(train_data['permission-data'],
            train_data['target'], test_size=0.3, random_state=1)


    selector = SelectKBest(chi2, k=15)
    x_train=selector.fit_transform(x_train,y_train)
    x_test=selector.transform(x_test)

    y_train=label_binarize(y_train, classes=['music-audio','personalization', 'social','communication'])
    y_test=label_binarize(y_test, classes=['music-audio','personalization', 'social','communication'])
    n_classes=4

    clss=[OneVsRestClassifier(MultinomialNB())]
    for cls in clss:
        model = cls.fit(x_train, y_train)
        # # valid the model
        y_score=model.predict_proba(x_test)

        fpr = dict()
        tpr = dict()
        roc_auc = dict()

        for i in range(4):
            fpr[i], tpr[i], _ = metrics.roc_curve(y_test[:,i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
        roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))

        # Then interpolate all ROC curves at this points
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += interp(all_fpr, fpr[i], tpr[i])

        # Finally average it and compute AUC
        mean_tpr /= n_classes

        fpr["macro"] = all_fpr
        tpr["macro"] = mean_tpr
        roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

        plt.figure()
        plt.plot(fpr["micro"], tpr["micro"],
                 label='micro-average ROC curve (area = {0:0.2f})'
                       ''.format(roc_auc["micro"]),
                 linewidth=2)

        plt.plot(fpr["macro"], tpr["macro"],
                 label='macro-average ROC curve (area = {0:0.2f})'
                       ''.format(roc_auc["macro"]),
                 linewidth=2)

        for i in range(4):
            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'
                                           ''.format(i, roc_auc[i]))

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Some extension of Receiver operating characteristic to multi-class')
        plt.legend(loc="lower right")
        plt.show()

def roc_test():
     y = np.array(['a', 'c', 'd', 'e'])
     scores = np.array([0.1, 0.4, 0.35, 0.8])
     fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)



def string_permission():

    # get data
    train_data,permission_list=db_tool.get_new_train_data()

    X_train=train_data['permission'].v
    x_train, x_test, y_train, y_test = cross_validation.train_test_split(train_data['permission-data'],
            train_data['target'], test_size=0.3, random_state=1)


    permission_selector = SelectKBest(chi2, k=15)
    x_train=permission_selector.fit_transform(x_train,y_train)
    x_test=permission_selector.transform(x_test)




    clss=[MultinomialNB()]
    for cls in clss:
        model = cls.fit(x_train, y_train)
        # # valid the model
        y_score=model.predict_proba(x_test)

        fpr = dict()
        tpr = dict()
        roc_auc = dict()

        for i in range(4):
            fpr[i], tpr[i], _ = metrics.roc_curve(y_test[:,i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
        roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))

        # Then interpolate all ROC curves at this points
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += interp(all_fpr, fpr[i], tpr[i])

        # Finally average it and compute AUC
        mean_tpr /= n_classes

        fpr["macro"] = all_fpr
        tpr["macro"] = mean_tpr
        roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

        plt.figure()
        plt.plot(fpr["micro"], tpr["micro"],
                 label='micro-average ROC curve (area = {0:0.2f})'
                       ''.format(roc_auc["micro"]),
                 linewidth=2)

        plt.plot(fpr["macro"], tpr["macro"],
                 label='macro-average ROC curve (area = {0:0.2f})'
                       ''.format(roc_auc["macro"]),
                 linewidth=2)

        for i in range(4):
            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'
                                           ''.format(i, roc_auc[i]))

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Some extension of Receiver operating characteristic to multi-class')
        plt.legend(loc="lower right")
        plt.show()

permission_roc()